{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 12:22:49.806025: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-25 12:22:49.933269: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-25 12:22:50.446146: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-25 12:22:50.446192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-25 12:22:50.446198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n",
      "Número de GPUs disponíveis:  2\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 12:22:51.199587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-25 12:22:51.200400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-25 12:22:51.209273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-25 12:22:51.210135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-25 12:22:51.210933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-25 12:22:51.211709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Input, Concatenate, GlobalAveragePooling2D, Reshape, Dense, Multiply\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import config\n",
    "import json\n",
    "import numpy as np\n",
    "import optuna\n",
    "from segmentation_models.metrics import iou_score, IOUScore, FScore\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from math import ceil\n",
    "\n",
    "# TF CONFIGURATION\n",
    "print(\"Número de GPUs disponíveis: \", len(\n",
    "    tf.config.list_physical_devices('GPU')))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU') #força usar a 0\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True) #so usa memoria a medida q precisa\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset -> (leitura - pré_processamento - generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN - caminho das pastas\n",
    "train_images_path = \"Dataset/train/Images_Cropped\"\n",
    "train_masks_path = \"Dataset/train/Masks_Cropped\"\n",
    "#VAL\n",
    "val_images_path = \"Dataset/val/Images_Cropped\"\n",
    "val_masks_path = \"Dataset/val/Masks_Cropped\"\n",
    "#TEST\n",
    "test_images_path = \"Dataset/test/Images_Cropped\"\n",
    "test_masks_path = \"Dataset/test/Masks_Cropped\"\n",
    "\n",
    "#TRAIN - lista com todos os nomes dos arquivos de imagem\n",
    "train_images_list = os.listdir(train_images_path)\n",
    "train_masks_list = os.listdir(train_masks_path)\n",
    "#VAL\n",
    "val_images_list = os.listdir(val_images_path)\n",
    "val_masks_list = os.listdir(val_masks_path)\n",
    "#TEST\n",
    "test_images_list = os.listdir(test_images_path)\n",
    "test_masks_list = os.listdir(test_masks_path)\n",
    "\n",
    "#TRAIN - ordenação dos nomes dos arquivos\n",
    "train_images_list.sort()\n",
    "train_masks_list.sort()\n",
    "#VAL\n",
    "val_images_list.sort()\n",
    "val_masks_list.sort()\n",
    "#VAL\n",
    "test_images_list.sort()\n",
    "test_masks_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mask_generator(images_list, images_path, masks_path, batch_size= config.BATCH_SIZE, output_size=config.IMAGE_SIZE):\n",
    "    num_samples = len(images_list)\n",
    "    while True:\n",
    "        # Embaralhar os índices para garantir que os dados sejam apresentados de forma aleatória\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            \n",
    "            batch_masks = []\n",
    "            for idx in batch_indices:\n",
    "                img_filename = os.path.join(images_path, images_list[idx])\n",
    "                mask_filename = os.path.join(masks_path, images_list[idx][:-4] + \".png\")\n",
    "\n",
    "                if not os.path.isfile(img_filename) or not os.path.isfile(mask_filename):\n",
    "                    print(f\"Arquivo de imagem ou máscara não encontrado: {images_list[idx]}\")\n",
    "                    continue\n",
    "\n",
    "                img = cv2.imread(img_filename)\n",
    "                mask = cv2.imread(mask_filename, cv2.IMREAD_UNCHANGED) #cv2.IMREAD_GRAYSCALE\n",
    "                \n",
    "                if img is None or mask is None:\n",
    "                    print(f\"Falha ao carregar imagem ou máscara: {images_list[idx]}\")\n",
    "                    continue\n",
    "\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, output_size)\n",
    "                mask = cv2.resize(mask, output_size, interpolation=cv2.INTER_NEAREST)\n",
    "                \n",
    "                img = img.astype(np.float32) / 255.0\n",
    "                mask = tf.one_hot(mask, 3)\n",
    "\n",
    "                batch_images.append(img)\n",
    "                batch_masks.append(mask)\n",
    "\n",
    "            yield np.array(batch_images), np.array(batch_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN\n",
    "gerador_treino = image_mask_generator(train_images_list, train_images_path, train_masks_path)\n",
    "#VAL\n",
    "gerador_validacao = image_mask_generator(val_images_list, val_images_path, val_masks_path)\n",
    "#TEST\n",
    "gerador_teste = image_mask_generator(test_images_list, test_images_path, test_masks_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construção do modelo Unet, com backbone EfficientNet e blocos Squeeze-Excitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Função Squeeze Excitation \"\"\"\n",
    "# def SqueezeAndExcitation(inputs, ratio=8):\n",
    "#   b, h, w, c = inputs.shape\n",
    "\n",
    "#   ## Squeeze\n",
    "#   x = GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "#   ## Excitation\n",
    "#   x = Dense(c//ratio, activation = 'relu', use_bias=False)(x)\n",
    "#   x = Dense(c, activation = 'sigmoid', use_bias=False)(x)\n",
    "\n",
    "#   ## Scaling\n",
    "#   x = inputs * x\n",
    "\n",
    "#   return x\n",
    "\n",
    "\n",
    "def SqueezeAndExcitation(inputs, ratio=8):\n",
    "    b, h, w, c = inputs.shape\n",
    "\n",
    "    ## Squeeze\n",
    "    x = GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "    ## Excitation\n",
    "    x = Dense(c//ratio, activation='relu', use_bias=False, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dense(c, activation='sigmoid', use_bias=False, kernel_regularizer=l2(0.01))(x)\n",
    "\n",
    "    ## Ensure x has dimensions (batch_size, 1, 1, channels)\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "\n",
    "    ## Scaling\n",
    "    x = inputs * x\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding='same', kernel_regularizer=l2(0.01))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same', kernel_regularizer=l2(0.01))(inputs)\n",
    "    # Applying SE block\n",
    "    x = SqueezeAndExcitation(x)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_efficient_unet(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" Pre-trained Encoder \"\"\"\n",
    "    encoder = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    encoder.summary()\n",
    "\n",
    "    s1 = encoder.get_layer(\"input_1\").output                          ## 256\n",
    "    s2 = encoder.get_layer(\"block2a_expand_activation\").output       ## 128\n",
    "    s3 = encoder.get_layer(\"block3a_expand_activation\").output        ## 64\n",
    "    s4 = encoder.get_layer(\"block4a_expand_activation\").output        ## 32\n",
    "\n",
    "    \"\"\" Bottleneck \"\"\"\n",
    "    b1 = encoder.get_layer(\"block6a_expand_activation\").output        ## 16\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)                                    ## 32\n",
    "    d2 = decoder_block(d1, s3, 256)                                    ## 64\n",
    "    d3 = decoder_block(d2, s2, 128)                                    ## 128\n",
    "    d4 = decoder_block(d3, s1, 64)                                     ## 265\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(3, 1, padding=\"same\", activation='softmax')(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"EfficientNetB0_UNET\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = build_efficient_unet(input_shape=(224,224,3))\n",
    "modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= config.LEARNING_RATE),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics= [IOUScore(class_indexes=1, threshold=0.5, name='iou_disco'), IOUScore(class_indexes=2, threshold=0.5, name='iou_cup'), FScore(class_indexes=1, threshold=0.5, name='dice_disco'), FScore(class_indexes=2, threshold=0.5, name='dice_cup')  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 12:22:59.636039: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700\n",
      "2024-02-25 12:23:00.012549: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 31.4655 - iou_disco: 0.5708 - iou_cup: 0.3648 - dice_disco: 0.7093 - dice_cup: 0.5284\n",
      "Epoch 1: val_iou_cup did not improve from 0.80000\n",
      "50/50 [==============================] - 20s 244ms/step - loss: 31.4655 - iou_disco: 0.5708 - iou_cup: 0.3648 - dice_disco: 0.7093 - dice_cup: 0.5284 - val_loss: 26.1199 - val_iou_disco: 4.9774e-11 - val_iou_cup: 1.5099e-10 - val_dice_disco: 4.9774e-11 - val_dice_cup: 1.5099e-10\n",
      "Epoch 2/2\n",
      "50/50 [==============================] - ETA: 0s - loss: 21.3250 - iou_disco: 0.6983 - iou_cup: 0.4922 - dice_disco: 0.8217 - dice_cup: 0.6570\n",
      "Epoch 2: val_iou_cup did not improve from 0.80000\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 21.3250 - iou_disco: 0.6983 - iou_cup: 0.4922 - dice_disco: 0.8217 - dice_cup: 0.6570 - val_loss: 18.2217 - val_iou_disco: 0.5025 - val_iou_cup: 1.5133e-10 - val_dice_disco: 0.6685 - val_dice_cup: 1.5133e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0300851b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrain model decoder\n",
    "callbacks_list = [EarlyStopping(monitor = 'val_iou_cup', patience = 25, mode = 'auto', verbose = 1), ModelCheckpoint(f\"/home/arthur_guilherme/pibic_mack-24/segmentation_refuge/checkpoint/best_model_weights.h5\", monitor = 'val_iou_cup', verbose = 1, save_best_only = True,save_weights_only = True, mode= 'max', initial_value_threshold=0.8)]\n",
    "\n",
    "\n",
    "modelo.fit(gerador_treino, \n",
    "           validation_data = gerador_validacao,\n",
    "           epochs= config.EPOCHS,\n",
    "           callbacks = callbacks_list,\n",
    "           steps_per_epoch= ceil(len(train_images_list)/config.BATCH_SIZE),\n",
    "           validation_steps= ceil(len(val_images_list)/config.BATCH_SIZE),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "# Definindo a métrica Dice\n",
    "def dice_metric(y_true, y_pred):\n",
    "    return dice_coefficient(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   input_shape = ((224, 2, 3))\n",
    "#   modelo = build_efficient_unet(input_shape)\n",
    "#   modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, test_generator, num_batches):\n",
    "    # Inicializa as listas para armazenar as métricas de cada batch\n",
    "    iou_scores = []\n",
    "    dice_scores = []\n",
    "    accuracies = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Itera sobre os batches do gerador até alcançar o número desejado de batches\n",
    "    for _ in range(num_batches):\n",
    "        # Obtém o próximo batch de dados do gerador\n",
    "        batch_images, batch_labels = next(test_generator)\n",
    "        \n",
    "        # Faz previsões usando o modelo no batch atual\n",
    "        predicts = model.predict(batch_images)\n",
    "        \n",
    "        # Converte as previsões em máscaras binárias\n",
    "        pred_masks = np.argmax(predicts, axis=-1)\n",
    "        \n",
    "        # Converte as máscaras verdadeiras para o formato binário\n",
    "        true_masks = np.argmax(batch_labels, axis=-1)\n",
    "        \n",
    "        # Calcula métricas para o batch atual\n",
    "        intersection = np.logical_and(true_masks, pred_masks)\n",
    "        union = np.logical_or(true_masks, pred_masks)\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        \n",
    "        dice_score = (2 * np.sum(intersection)) / (np.sum(true_masks) + np.sum(pred_masks))\n",
    "        \n",
    "        accuracy = sklearn.metrics.accuracy_score(true_masks.flatten(), pred_masks.flatten())\n",
    "        recall = sklearn.metrics.recall_score(true_masks.flatten(), pred_masks.flatten(), average='weighted')\n",
    "        f1_score = sklearn.metrics.f1_score(true_masks.flatten(), pred_masks.flatten(), average='weighted')\n",
    "        \n",
    "        # Armazena as métricas do batch atual\n",
    "        iou_scores.append(iou_score)\n",
    "        dice_scores.append(dice_score)\n",
    "        accuracies.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "        \n",
    "    # Calcula as métricas médias para os batches processados\n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    mean_dice = np.mean(dice_scores)\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    # Imprime as métricas médias\n",
    "    print(f\"Mean IoU (Jaccard Index): {mean_iou}\")\n",
    "    print(f\"Mean Dice Coefficient: {mean_dice}\")\n",
    "    print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "    print(f\"Mean Recall: {mean_recall}\")\n",
    "    print(f\"Mean F1-score: {mean_f1_score}\")\n",
    "    \n",
    "    return mean_iou, mean_dice, mean_accuracy, mean_recall, mean_f1_score\n",
    "\n",
    "evaluation(modelo, gerador_treino, num_batches=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mackele_a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
